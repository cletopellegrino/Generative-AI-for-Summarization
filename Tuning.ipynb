{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9427e9e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T14:52:54.707464Z",
     "iopub.status.busy": "2024-05-19T14:52:54.706683Z",
     "iopub.status.idle": "2024-05-19T14:53:54.724263Z",
     "shell.execute_reply": "2024-05-19T14:53:54.723199Z",
     "shell.execute_reply.started": "2024-05-19T14:52:54.707432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert_score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.1.2)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.1.4)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.39.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert_score) (1.26.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.66.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.7.5)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert_score) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert_score) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score) (2023.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.22.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.4.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (9.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert_score) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bert_score\n",
      "Successfully installed bert_score-0.3.13\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=904929d58c420fd04e3aa5fb4e726ddf236bd7b9a207e1a967f5839ed1442c29\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 14:53:44.234526: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-19 14:53:44.234628: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-19 14:53:44.374791: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/tmp/ipykernel_34/1980692075.py:9: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"rouge\")\n",
      "/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc1767c3d0346b38bbb365f338ae603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install bert_score\n",
    "!pip install rouge_score\n",
    "!pip install datasets\n",
    "\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "from datasets import load_metric, Dataset\n",
    "metric = load_metric(\"rouge\")\n",
    "from bert_score import score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "109d1cf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T14:53:54.726525Z",
     "iopub.status.busy": "2024-05-19T14:53:54.725962Z",
     "iopub.status.idle": "2024-05-19T14:54:04.077277Z",
     "shell.execute_reply": "2024-05-19T14:54:04.076303Z",
     "shell.execute_reply.started": "2024-05-19T14:53:54.726498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d589f9b093d04528816f48b6c4360215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18d311b1cb141f198b0ce51ab0b5e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849d6141bbec435d8b95f52817850e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7830dd0be43647c4ba59151d6aeea36a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a24fcb9a3e94cb0b689d057bab8f096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5821702867f646e38f8c44b0755ca696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc1ee32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T14:54:04.078880Z",
     "iopub.status.busy": "2024-05-19T14:54:04.078589Z",
     "iopub.status.idle": "2024-05-19T14:54:04.084033Z",
     "shell.execute_reply": "2024-05-19T14:54:04.083042Z",
     "shell.execute_reply.started": "2024-05-19T14:54:04.078853Z"
    }
   },
   "outputs": [],
   "source": [
    "MIN_ALLOWED_SEQUENCE = 30\n",
    "MAX_ALLOWED_SEQUENCE = 2048\n",
    "BATCH_SIZE = 1\n",
    "ACCUMULATION_STEPS = 4\n",
    "LEARNING_RATE = 1e-6\n",
    "EPOCHS = 20\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28a56ed0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T14:54:04.087141Z",
     "iopub.status.busy": "2024-05-19T14:54:04.086696Z",
     "iopub.status.idle": "2024-05-19T14:54:04.095157Z",
     "shell.execute_reply": "2024-05-19T14:54:04.094237Z",
     "shell.execute_reply.started": "2024-05-19T14:54:04.087107Z"
    }
   },
   "outputs": [],
   "source": [
    "model.config.max_length = MAX_ALLOWED_SEQUENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b036dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T14:54:04.097053Z",
     "iopub.status.busy": "2024-05-19T14:54:04.096439Z",
     "iopub.status.idle": "2024-05-19T14:54:04.106400Z",
     "shell.execute_reply": "2024-05-19T14:54:04.105532Z",
     "shell.execute_reply.started": "2024-05-19T14:54:04.097027Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    references = [\"summarize: \" + ref for ref in examples[\"reference\"]]\n",
    "    \n",
    "    inputs = tokenizer(references, truncation=True, max_length=MAX_ALLOWED_SEQUENCE)\n",
    "    targets = tokenizer(examples[\"summary\"], truncation=True, max_length=MAX_ALLOWED_SEQUENCE)\n",
    "\n",
    "    # Update examples with tokenized inputs and targets\n",
    "    return {\"input_ids\": inputs.input_ids, \"attention_mask\": inputs.attention_mask, \"labels\": targets.input_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9de341e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T14:54:04.108290Z",
     "iopub.status.busy": "2024-05-19T14:54:04.107963Z",
     "iopub.status.idle": "2024-05-19T14:54:12.569341Z",
     "shell.execute_reply": "2024-05-19T14:54:12.568373Z",
     "shell.execute_reply.started": "2024-05-19T14:54:04.108259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c44c238268a46bf8549e276244b6ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/438 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1dcff9905746cf820d65a9859d8991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train_processed.csv\")\n",
    "valid_df = pd.read_csv(\"validation_processed.csv\")\n",
    "\n",
    "train_df = train_df[train_df['reference_tokens_preprocessed'] < MAX_ALLOWED_SEQUENCE].reset_index(drop=True)\n",
    "valid_df = valid_df[valid_df['reference_tokens_preprocessed'] < MAX_ALLOWED_SEQUENCE].reset_index(drop=True)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "valid_dataset = Dataset.from_pandas(valid_df)\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "valid_dataset = valid_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ac9b8d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T14:54:12.570644Z",
     "iopub.status.busy": "2024-05-19T14:54:12.570389Z",
     "iopub.status.idle": "2024-05-19T14:54:12.580368Z",
     "shell.execute_reply": "2024-05-19T14:54:12.579492Z",
     "shell.execute_reply.started": "2024-05-19T14:54:12.570620Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    # Calculate ROUGE score\n",
    "    rouge_result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    rouge_result = {key: value.mid.fmeasure * 100 for key, value in rouge_result.items()}\n",
    "    \n",
    "    # Calculate BERTScore\n",
    "    P, R, F1 = score(decoded_preds, decoded_labels, lang='en', verbose=False)\n",
    "    bertscore_result = {\n",
    "        \"bert_precision\": P.mean().item() * 100,\n",
    "        \"bert_recall\": R.mean().item() * 100,\n",
    "        \"bert_f1\": F1.mean().item() * 100\n",
    "    }\n",
    "    \n",
    "    # Calculate average prediction length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    gen_len = np.mean(prediction_lens)\n",
    "    \n",
    "    result = {**rouge_result, **bertscore_result, \"gen_len\": gen_len}\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98ab9b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T14:54:12.581993Z",
     "iopub.status.busy": "2024-05-19T14:54:12.581644Z",
     "iopub.status.idle": "2024-05-19T14:54:12.888875Z",
     "shell.execute_reply": "2024-05-19T14:54:12.888086Z",
     "shell.execute_reply.started": "2024-05-19T14:54:12.581960Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./my_fine_tuned_t5_small_model\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    predict_with_generate=True,\n",
    "    gradient_accumulation_steps=ACCUMULATION_STEPS,\n",
    "    eval_accumulation_steps=ACCUMULATION_STEPS,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60c53a89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T14:54:12.890205Z",
     "iopub.status.busy": "2024-05-19T14:54:12.889937Z",
     "iopub.status.idle": "2024-05-19T15:30:03.313482Z",
     "shell.execute_reply": "2024-05-19T15:30:03.312448Z",
     "shell.execute_reply.started": "2024-05-19T14:54:12.890180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2180' max='2180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2180/2180 35:48, Epoch 19/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Bert Precision</th>\n",
       "      <th>Bert Recall</th>\n",
       "      <th>Bert F1</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>7.535876</td>\n",
       "      <td>12.289500</td>\n",
       "      <td>5.144900</td>\n",
       "      <td>8.961100</td>\n",
       "      <td>11.513300</td>\n",
       "      <td>85.387000</td>\n",
       "      <td>78.257300</td>\n",
       "      <td>81.656500</td>\n",
       "      <td>76.571400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.462596</td>\n",
       "      <td>12.838300</td>\n",
       "      <td>5.154300</td>\n",
       "      <td>9.334700</td>\n",
       "      <td>12.083200</td>\n",
       "      <td>85.051000</td>\n",
       "      <td>78.272100</td>\n",
       "      <td>81.512300</td>\n",
       "      <td>82.214300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.610200</td>\n",
       "      <td>3.954201</td>\n",
       "      <td>13.478700</td>\n",
       "      <td>6.071500</td>\n",
       "      <td>9.887900</td>\n",
       "      <td>12.627200</td>\n",
       "      <td>85.453000</td>\n",
       "      <td>78.533200</td>\n",
       "      <td>81.838900</td>\n",
       "      <td>84.214300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.610200</td>\n",
       "      <td>3.715705</td>\n",
       "      <td>13.445600</td>\n",
       "      <td>5.365900</td>\n",
       "      <td>9.654100</td>\n",
       "      <td>12.493300</td>\n",
       "      <td>84.434000</td>\n",
       "      <td>78.127400</td>\n",
       "      <td>81.145800</td>\n",
       "      <td>90.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6.610200</td>\n",
       "      <td>3.596324</td>\n",
       "      <td>13.250900</td>\n",
       "      <td>5.327500</td>\n",
       "      <td>9.368000</td>\n",
       "      <td>12.306500</td>\n",
       "      <td>84.620700</td>\n",
       "      <td>78.221600</td>\n",
       "      <td>81.287200</td>\n",
       "      <td>86.357100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.256000</td>\n",
       "      <td>3.522705</td>\n",
       "      <td>14.125000</td>\n",
       "      <td>6.034500</td>\n",
       "      <td>10.256500</td>\n",
       "      <td>13.148500</td>\n",
       "      <td>84.682700</td>\n",
       "      <td>78.435400</td>\n",
       "      <td>81.430800</td>\n",
       "      <td>92.857100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.256000</td>\n",
       "      <td>3.475759</td>\n",
       "      <td>14.291800</td>\n",
       "      <td>5.918900</td>\n",
       "      <td>10.097500</td>\n",
       "      <td>13.164500</td>\n",
       "      <td>84.597400</td>\n",
       "      <td>78.430000</td>\n",
       "      <td>81.387400</td>\n",
       "      <td>94.857100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.996200</td>\n",
       "      <td>3.446184</td>\n",
       "      <td>14.423800</td>\n",
       "      <td>5.967700</td>\n",
       "      <td>10.207400</td>\n",
       "      <td>13.358400</td>\n",
       "      <td>84.510400</td>\n",
       "      <td>78.429400</td>\n",
       "      <td>81.348000</td>\n",
       "      <td>95.571400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.996200</td>\n",
       "      <td>3.428485</td>\n",
       "      <td>14.106100</td>\n",
       "      <td>5.789400</td>\n",
       "      <td>10.064800</td>\n",
       "      <td>13.053400</td>\n",
       "      <td>84.427100</td>\n",
       "      <td>78.350800</td>\n",
       "      <td>81.266600</td>\n",
       "      <td>95.214300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.915900</td>\n",
       "      <td>3.420532</td>\n",
       "      <td>14.129200</td>\n",
       "      <td>5.787200</td>\n",
       "      <td>10.091100</td>\n",
       "      <td>13.114000</td>\n",
       "      <td>84.428900</td>\n",
       "      <td>78.352400</td>\n",
       "      <td>81.268300</td>\n",
       "      <td>95.285700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.915900</td>\n",
       "      <td>3.419768</td>\n",
       "      <td>14.129200</td>\n",
       "      <td>5.787200</td>\n",
       "      <td>10.091100</td>\n",
       "      <td>13.114000</td>\n",
       "      <td>84.428900</td>\n",
       "      <td>78.352400</td>\n",
       "      <td>81.268300</td>\n",
       "      <td>95.285700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1197: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd4ad38d2604802810f0f282eda5de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6faca31cac945f8be3b2fff80ceb569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057516afb3a442fb952d22e37db5453c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5570293f704d61af9689954e0650c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ffe687ef294849afc77820478bf0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165c3fce9c82457c9e769c77b0ad859b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 2048}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2180, training_loss=4.62855342200043, metrics={'train_runtime': 2150.1089, 'train_samples_per_second': 4.074, 'train_steps_per_second': 1.014, 'total_flos': 2873064045969408.0, 'train_loss': 4.62855342200043, 'epoch': 19.91})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc3fee1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:30:03.316434Z",
     "iopub.status.busy": "2024-05-19T15:30:03.316073Z",
     "iopub.status.idle": "2024-05-19T15:30:03.566601Z",
     "shell.execute_reply": "2024-05-19T15:30:03.565756Z",
     "shell.execute_reply.started": "2024-05-19T15:30:03.316408Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test_processed.csv\")\n",
    "test_df = test_df[test_df['reference_tokens_preprocessed'] < MAX_ALLOWED_SEQUENCE].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee17249c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:35:14.930554Z",
     "iopub.status.busy": "2024-05-19T15:35:14.930186Z",
     "iopub.status.idle": "2024-05-19T15:36:06.581142Z",
     "shell.execute_reply": "2024-05-19T15:36:06.580161Z",
     "shell.execute_reply.started": "2024-05-19T15:35:14.930522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the commission ( eurostat ) shall adopt delegated act in accordance with the principle laid down in the interinstitutional agreement of 13 april 2016 on better law-making. the commission ( eurostat ) shall establish a formal expert group, composed of representative of all the member state and chaired by a representative of the commission ( eurostat ). the commission ( eurostat ) shall establish a formal expert group, composed of representative of all the member state and chaired by\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.80\n",
      "article 1 subject matter the year 2021 shall be designated a ‘ european year of rail ’. the specific objective of the european year shall be to encourage and support the effort of the union, member state, regional and local authority, and other organisation to increase the share of passenger and freight moving by rail. the commission shall regularly convene meeting of the national contact person in order to coordinate the running of the european year.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.84\n",
      "the european union recovery instrument ( the ‘ instrument ’ ) shall be carried out under specific union programme and in accordance with the objective of the instrument. the instrument shall be financed up to an amount of eur 750 000 million in 2018 price on the basis of the empowerment provided for in article 5 of the own resource decision. the measure shall be carried out under specific union programme and in accordance with the relevant union act laying down rule for those programme.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.81\n",
      "article 1 subject matter this regulation establishes common rule for the decennial provision of comprehensive data on population and housing. article 2 definition for the purpose of this regulation establishes common rule for the decennial provision of comprehensive data on population and housing. article 2 definition for the purpose of this regulation establishes common rule for the decennial provision of comprehensive data on population and housing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.80\n",
      "article 1 the strategic innovation agenda of the european institute of innovation and technology for the period from 2021 to 2027 ( sia 2021-2027 ) a set out in the annex is hereby adopted. article 3 decision no 1312/2013/eu is repealed with effect from 1 january 2021.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.82\n",
      "the commission ( eurostat ) shall submit a report on the implementation of the regulation ( ec ) no 1107/2009. the commission ( eurostat ) shall adopt the definition of the ‘ area treated ’ a referred to in section 2 of regulation ( ec ) no 1107/2009. the commission ( eurostat ) shall submit a report on the implementation of the regulation ( ec ) no 223/2009.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.75\n",
      "the measure referred to in article 4 shall be adopted in respect of country allowing non-sustainable fishing. the commission shall provide the country concerned with a reasonable opportunity to respond to the notification in writing and to remedy the situation within one month of receiving that notification. the measure referred to in article 4 shall be a framework for the adoption of certain measure regarding the conservation and management of the stock of common interest to the union and those third country. the measure referred to in article 4 shall provide for an appropriate system for their enforcement by\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.82\n",
      "the fado system may contain information on authentic document issued by member state, the union and third party, such a third country, territorial entity, international organisation and other entity subject to international law, and on false version thereof. the fado system may contain information on travel, identity, residence and civil status document, driving licence and vehicle licence issued by member state, such a third country, territorial entity, international organisation and other entity subject to international law, and\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.83\n",
      "an authorised entity established in a member state carrying out the act referred to in article 3 and 4 shall establish and follow it own practice to ensure that it distributes, communicates and make available accessible format copy only to beneficiary person or other authorised entity. an authorised entity established in a member state carrying out the act referred to in point 3 and 4 shall establish and follow it own practice to ensure that it : ( a ) distributes, communicates and make available accessible format copy only to beneficiary person or\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.79\n",
      "article 1 definition for the purpose of this regulation shall apply : ( 1 ) ‘ circulation coin ’ mean euro coin intended for circulation, the denomination and technical specification of which are laid down in regulation ( ec ) no 975/98 ; ( 2 ) ‘ commemorative coin ’ mean euro coin intended for collection that are not issued with a view to their entry into circulation. the commission shall conduct an impact assessment on the continued issuance of 1- and 2-cent coin. each member state whose currency is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.82\n",
      "the commission ( eurostat ) shall provide the commission ( eurostat ) with data on their population and vital event referred to in paragraph 1 ( ec ) no 223/2009 ( ec ) no 223/2009 ( ec ) no 223/2009 ( ec ) no 223/2009 ( ec ) no 223/2009 ( ec ) no 223/2009 ( ec ) no 223/2009 ( ec ) no 223/2009 ( e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.78\n",
      "this regulation lay down the community regime relating to liability and insurance for the carriage of passenger by sea a set out in annex ii. the commission shall, if appropriate, present a legislative proposal in order, inter alia, to extend the scope of this regulation to ship of class a and b. the liability regime in respect of passenger, their luggage and their vehicle shall be governed only by article 3 ( 3 ) of the athens convention. the commission shall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.81\n",
      "this regulation establishes a common framework for the systematic production of community statistic on public health and health and safety at work. the statistic shall include, in the form of a harmonised and common data set, information required for community action in the field of public health, for supporting national strategy for the development of high-quality, universally accessible and sustainable health care a well a for community action in the field of health and safety at work. the commission ( eurostat ) shall prepare a report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.82\n",
      "the commission ( eurostat ) shall provide data on job vacancy at least for business unit with one employee or more. the data shall cover all economic activity defined by the common classification system for economic activity in the community ( nace in force ), except for the activity of household a employer and the activity of extraterritorial organisation and body. the data shall be broken down by economic activity in accordance with the nace in force at section level.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.86\n",
      "a cohesion fund is hereby established for the purpose of strengthening the economic, social and territorial cohesion of the union in the interest of promoting sustainable development. the cohesion fund shall, while ensuring an appropriate balance and according to the investment and infrastructure need specific to each member state, support : (a ) investment in the environment, including area related to sustainable development and energy which present environmental benefit ; ( b ) investment in the water sector unless related to the promotion of energy efficiency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.82\n",
      "have adopted this regulation : article 1 subject matter this regulation establishes a common framework for the systematic production of community statistic in the field of education and lifelong learning. article 2 definition for the purpose of this regulation ( ec ) no 322/97 ; ( b ) ‘ production of statistic ’ shall be defined a in the second indent of article 2 of regulation ( ec ) no 322/97 ; ( c ) ‘ national authority ’ shall be defined a in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.82\n",
      "this regulation establishes a common framework for the production, transmission, evaluation and dissemination of comparable energy statistic in the community. this regulation establishes a common framework for the production, transmission, evaluation and dissemination of comparable energy statistic in the community. the commission ( eurostat ) shall present and disseminate the national statistic referred to in article 11 ( 2 ).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.82\n",
      "have adopted this regulation : article 1 obligation of the member state member state shall submit to the commission statistic on all the aquaculture activity conducted in freshwater and saltwater on their territory. article 2 definition 1. for the purpose of this regulation, the following definition shall apply : ( a ) ‘ community statistic ’ a defined in article 2 of regulation ( ec ) no 322/97 ; ( b ) ‘ capture-based aquaculture ’ mean the practice of collecting specimen from the wild and their subsequent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.82\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8139538235134549"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_results = []\n",
    "device = torch.device(\"cuda\")\n",
    "model_trained = T5ForConditionalGeneration.from_pretrained(\"./my_fine_tuned_t5_small_model/checkpoint-2080\").to(device)\n",
    "\n",
    "#MIN_ALLOWED_SEQUENCE = 30\n",
    "#MAX_ALLOWED_SEQUENCE = 2048\n",
    "NUM_BEAMS = 4\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    inputs = tokenizer(\"summarize: \" + row[\"reference\"], max_length=MAX_ALLOWED_SEQUENCE, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    outputs = model_trained.generate(**inputs, min_length=MIN_ALLOWED_SEQUENCE, max_length=MAX_ALLOWED_SEQUENCE,\\\n",
    "                                        num_beams=NUM_BEAMS, early_stopping=True)\n",
    "    result_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(result_summary)\n",
    "\n",
    "    P, R, F1 = score([result_summary], [row[\"summary\"]], lang='en', verbose=False)\n",
    "    print(f\"T5 BertScore F1: {F1.item():.2f}\")\n",
    "    trained_results.append(F1.item())\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "np.mean(trained_results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87f7d560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:30:52.651933Z",
     "iopub.status.busy": "2024-05-19T15:30:52.651289Z",
     "iopub.status.idle": "2024-05-19T15:33:10.318357Z",
     "shell.execute_reply": "2024-05-19T15:33:10.317404Z",
     "shell.execute_reply.started": "2024-05-19T15:30:52.651882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7557718082c8460d9a20282bf0049c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6295352a64e44a0abf01e9b4afb85470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021060d4b20b4a5aa312764f9172c363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53151cae4dd24552b540d5452face34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d182b0cd8ae43a8a097f74f5c4f1ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:246: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on google-t5/t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gross national income at market price ( gni ) and gross domestic product at market price ( gdp ) shall be defined in accordance with the european system of account 2010 ( esa 2010 ) established by regulation ( eu ) no 549/2013. member state shall calculate gni in the context of national accounting procedure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.85\n",
      "the year 2021 shall be designated a the ‘ european year of rail’. the general objective of the european year shall be to encourage and support the effort of the union, member state, regional and local authority. by 31 march 2021, the commission shall inform the european parliament and the council of it plan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.83\n",
      "support under the instrument shall in particular finance measures to tackle the adverse economic consequence of the covid-19 crisis. legal commitment of at least 60 % of the amount referred to in point ( a ) of article 2 ( 2 ) shall be entered into by 31 december 2022. decision on the granting of the loan referred to in point ( b ) of article 2 ( 2 ) shall be adopted by 31 december 2023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.79\n",
      "member state shall submit to the commission ( eurostat ) data on the population covering determined demographic, social and economic characteristic. reference date shall fall in a year specified on the basis of this regulation. member state shall provide the commission ( eurostat ) with a report on the quality of the data transmitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.84\n",
      "sia 2021-2027 shall be implemented in accordance with regulation ( eu ) 2021/819. decision no 1312/2013/eu is repealed with effect from 1 january 2021.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.80\n",
      "this regulation establishes a common framework for the systematic production of community statistic on the placing on the market and use of those pesticide. statistic shall apply to : — the annual amount of pesticide placed on the market in accordance with annex i.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.74\n",
      "measure may apply where cooperation between third country and the union is required for the joint management of the stock of common interest. a country may be identified a a country allowing non-sustainable fishing where it fails to cooperate in the management of a stock of common interest. the measure referred to in article 4 shall cease to apply when the country allowing non-sustainable fishing adopts appropriate corrective measure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.84\n",
      "fado system contains information on authentic document issued by member state. also contains information on false document issued by third party. purpose of fado system is to contribute to fight against document and identity fraud.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.84\n",
      "authorised entity established in a member state shall establish and follow its own practice to ensure it distributes, communicates and make available accessible format copy. an authorised entity established in a member state shall provide the following information in an accessible way. an authorised entity established in a member state carrying out the act referred to in article 3 and 4 shall provide the following information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.80\n",
      "circulation coin means euro coin intended for circulation. commemorative coin means circulation coin intended to commemorate a specific subject. collector coin means euro coin intended for collection that are not issued with a view to their entry into circulation. member state may issue two commemorative coin per year.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.81\n",
      "the regulation establishes a common legal framework for the development, production and dissemination of european statistic on population and vital event. member state shall provide the commission ( eurostat ) with data on their usually resident population at the reference time. data shall cover population by age, sex and region of residence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.82\n",
      "this regulation shall apply to carriage of passenger by sea within a single member state on board ship of class a and b under article 4 of directive 98/18/ec. it shall apply from the date of entry into force of the athens convention for the community, and in any case from no later than 31 december 2012. it shall be binding in it entirety and directly applicable in all member state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.81\n",
      "the statistic shall be produced in compliance with standard on impartiality, reliability, objectivity, cost-effectiveness and statistical confidentiality. member state shall ensure that the transmitted data do not permit the direct identification of the statistical unit ( individual )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.78\n",
      "each member state shall submit to the commission ( eurostat ) data on job vacancy at least for business unit with one employee or more. data shall cover all economic activity defined by the common classification system for economic activity in the community.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.85\n",
      "a cohesion fund is hereby established for the purpose of strengthening the economic, social and territorial cohesion of the union. it shall support investment for growth and job goal referred to in article 89 of regulation ( eu ) no 1303/2013. the cohesion fund shall not support. the decommissioning or the construction of nuclear power station.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.83\n",
      "this regulation establishes a common framework for the systematic production of community statistic in the field of education and lifelong learning. member state shall ensure that the transmitted data do not permit the direct identification of the statistical unit concerned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.82\n",
      "this regulation establishes a common framework for the production, transmission, evaluation and dissemination of comparable energy statistic in the community. member state shall compile data concerning energy product and their aggregate in the community. they shall be transmitted with the frequency laid out in the annex.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.82\n",
      "a member state shall submit to the commission statistic on all the aquaculture activity conducted in freshwater and saltwater on their territory. member state shall use survey or other statistically validated method covering at least 90 % of the total production by volume. the remaining part of the total production may be estimated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8173354268074036"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model_trained\n",
    "untrained_results = []\n",
    "device = torch.device(\"cuda\")\n",
    "model_untrained = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-large\").to(device)\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-large\")\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    inputs = tokenizer(\"summarize: \" + row[\"reference\"], max_length=MAX_ALLOWED_SEQUENCE, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    outputs = model_untrained.generate(**inputs, min_length=MIN_ALLOWED_SEQUENCE, max_length=MAX_ALLOWED_SEQUENCE,\\\n",
    "                                        num_beams=NUM_BEAMS, early_stopping=True)\n",
    "    result_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(result_summary)\n",
    "\n",
    "    P, R, F1 = score([result_summary], [row[\"summary\"]], lang='en', verbose=False)\n",
    "    print(f\"T5 BertScore F1: {F1.item():.2f}\")\n",
    "    untrained_results.append(F1.item())\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "np.mean(untrained_results)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a43e7e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:36:12.392408Z",
     "iopub.status.busy": "2024-05-19T15:36:12.391681Z",
     "iopub.status.idle": "2024-05-19T15:36:12.397714Z",
     "shell.execute_reply": "2024-05-19T15:36:12.396699Z",
     "shell.execute_reply.started": "2024-05-19T15:36:12.392373Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"trained.npy\", trained_results)\n",
    "np.save(\"untrained.npy\", untrained_results)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5040645,
     "sourceId": 8457132,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6114fa1f-34d2-48d6-b242-9fa415b94c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from bert_score import score\n",
    "\n",
    "train_df = pd.read_csv(\"dataset/train_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71865b10-ff3c-4cc7-8dad-8180195d863b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_t5 = T5Tokenizer.from_pretrained(\"google-t5/t5-large\")\n",
    "\n",
    "device = torch.device(\"cuda\") # GPU usage\n",
    "model_t5 = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-large\")\n",
    "model_t5.to(device)\n",
    "\n",
    "tokenizer_t5.model_max_length = 4096 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9585bbe-bfdb-4fd0-857d-cc6cf2efcb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadingWithJumpingWindow(model, tokenizer, text):\n",
    "    torch.cuda.empty_cache()\n",
    "    if len(text.split()) < tokenizer.model_max_length:\n",
    "        inputs = tokenizer(\"summarize: \" + text,\\\n",
    "                           return_tensors=\"pt\",\\\n",
    "                           max_length=tokenizer.model_max_length,\\\n",
    "                           truncation=True).to(device)\n",
    "        outputs = model.generate(**inputs, min_length=0, max_new_tokens=tokenizer.model_max_length)\n",
    "        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    JUMP = 100\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    start = 0\n",
    "\n",
    "    while start < len(words):\n",
    "        end = min(int(start + tokenizer.model_max_length + JUMP), len(words))\n",
    "        chunks.append(' '.join(words[int(start):int(start + tokenizer.model_max_length/2)]) \\\n",
    "                        + \" \" + ' '.join(words[int(start + tokenizer.model_max_length/2) + JUMP:end]))\n",
    "        start += tokenizer.model_max_length/2\n",
    "\n",
    "    print(len(chunks))\n",
    "    \n",
    "    summarized_chunks = []\n",
    "    for chunk in chunks:\n",
    "        inputs = tokenizer(\"summarize: \" + chunk,\\\n",
    "                           return_tensors=\"pt\",\\\n",
    "                           max_length=tokenizer.model_max_length,\\\n",
    "                           truncation=True).to(device)\n",
    "        outputs = model.generate(**inputs, min_length=0, max_new_tokens=tokenizer.model_max_length)\n",
    "        summarized_chunks.append(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    summarized_text = ' '.join(summarized_chunks)\n",
    "    \n",
    "    if len(summarized_text.split()) > tokenizer.model_max_length:\n",
    "        return ReadingWithJumpingWindow(model, tokenizer, summarized_text)\n",
    "    else:\n",
    "        inputs = tokenizer(\"summarize: \" + summarized_text,\\\n",
    "                           return_tensors=\"pt\",\\\n",
    "                           max_length=tokenizer.model_max_length,\\\n",
    "                           truncation=True).to(device)\n",
    "        outputs = model.generate(**inputs, min_length=0, max_new_tokens=tokenizer.model_max_length)\n",
    "        return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c8fa2d-9298-4d56-af1f-e665a46cf5b4",
   "metadata": {},
   "source": [
    "The following test was done to assess the performance on the model on texts that it can analyze without splitting it in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392ebc7a-68fe-40b1-8544-c029aa7e6a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654\n",
      "equipment using ultra-wideband technology is defined as equipment. equipment using ultra-wideband technology must meet technical condition. equipment using ultra-wideband technology must be used indoors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.79\n",
      "3116\n",
      "agreement shall apply to civil aviation regulatory system of the people's republic of china and the civil aviation regulatory system of the european union. parties agree to cooperate in all areas of civil aviation safety. agreement shall be binding on both parties and shall remain in force until terminated by either party.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.81\n",
      "92\n",
      "the technical specification for electronic ship reporting in inland navigation shall be a set out in the annex. regulation shall enter into force on the day following that of it publication in the official journal of the european union. it shall apply not later than 30 month after it entry into force.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.78\n",
      "2577\n",
      "eu regulation establishes requirement for the labelling of electric mains-operated refrigerating appliance with a direct sale function. it shall enter into force on the twentieth day following that of it publication in the official journal of the european union.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.81\n",
      "2877\n",
      "light source and separate control gear must comply with ecodesign requirement. they must be placed on the market in a containing product and be replaceable. light source and separate control gear must be available on a free-access website.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.80\n",
      "0.7979308128356933\n"
     ]
    }
   ],
   "source": [
    "F1_t5_less_4096 = []\n",
    "\n",
    "for index, row in train_df[train_df['reference_tokens'] < 4096][:5].iterrows():\n",
    "    reference_text = row[\"reference\"]\n",
    "    reference_summary = row[\"summary\"]\n",
    "    print(row[\"reference_tokens\"])\n",
    "\n",
    "    result_summary = ReadingWithJumpingWindow(model_t5, tokenizer_t5, reference_text)\n",
    "    print(result_summary)\n",
    "    P, R, F1 = score([result_summary], [reference_summary], lang='en', verbose=False)\n",
    "    print(f\"T5 BertScore F1: {F1.item():.2f}\")\n",
    "    F1_t5_less_4096.append(F1.item())\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "np.save('F1_t5_less_4096.npy', F1_t5_less_4096)\n",
    "\n",
    "sum = 0\n",
    "for _ in F1_t5_less_4096:\n",
    "    sum += _\n",
    "print(sum / len(F1_t5_less_4096))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f766a8ea-8d1c-4e62-94ee-f2e994ae883b",
   "metadata": {},
   "source": [
    "The following test was done to assess the performance on the model on texts that it must split in chunks to perform the summarization task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54d5da47-d120-4303-ad26-d1ca8f9cda05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8443\n",
      "5\n",
      "eu has adopted a set of rules to regulate the disclosure of information in prospectuses and security notes. the rules apply to all securities issued by a regulated market or by a third country. the information must be provided in the order in which they are required.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.80\n",
      "19979\n",
      "10\n",
      "account governed by the law and fall under the jurisdiction of the member state of their administrator. account holder may object to the suspension of access to account if it is not resolved within a reasonable period. account holder may report any fraud or suspected fraud to the competent national law enforcement authority.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.78\n",
      "5394\n",
      "3\n",
      "eu innovation fund is intended to support projects demonstrating high level of innovation. the fund is intended to be used to support projects reducing greenhouse gas emissions. the commission shall invite the proponent of those project to submit a full application.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.82\n",
      "7139\n",
      "4\n",
      "uas operator shall declare to the competent authority that they are able to carry out the operation. uas operator shall register themselves in the member state where they have their residence or principal place of business. uas operator shall provide the competent authority with the information required to carry out the operation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.79\n",
      "10476\n",
      "6\n",
      "eu regulation applies to uas intended to be operated in the 'open' category. it also applies to uas intended to be operated in the'specific' category. it establishes rule on making uas available on the market and their free movement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5 BertScore F1: 0.80\n",
      "0.7999849915504456\n"
     ]
    }
   ],
   "source": [
    "F1_t5_more_4096 = []\n",
    "\n",
    "for index, row in train_df[train_df['reference_tokens'] > 4096][:5].iterrows():\n",
    "    reference_text = row[\"reference\"]\n",
    "    reference_summary = row[\"summary\"]\n",
    "    print(row[\"reference_tokens\"])\n",
    "\n",
    "    result_summary = ReadingWithJumpingWindow(model_t5, tokenizer_t5, reference_text)\n",
    "    print(result_summary)\n",
    "    P, R, F1 = score([result_summary], [reference_summary], lang='en', verbose=False)\n",
    "    print(f\"T5 BertScore F1: {F1.item():.2f}\")\n",
    "    F1_t5_more_4096.append(F1.item())\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "np.save('F1_t5_more_4096.npy', F1_t5_more_4096)\n",
    "\n",
    "sum = 0\n",
    "for _ in F1_t5_more_4096:\n",
    "    sum += _\n",
    "print(sum / len(F1_t5_more_4096))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
